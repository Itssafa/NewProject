{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiR7QoxabVz8j//LcESHoG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Itssafa/NewProject/blob/main/claim_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVr5rbt1pV0_",
        "outputId": "30696a6f-a9fb-4c31-9aac-9cd8ece8cd3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Chargement et exploration des données\n",
            "Dimensions du dataset: (2000, 12)\n",
            "\n",
            "Aperçu des données:\n",
            "        sender    receiver  number_of_characters  contains_urgent  \\\n",
            "0  Electrician   Architect                   366            False   \n",
            "1    Architect   Architect                    44            False   \n",
            "2   Mechanical   Architect                    38            False   \n",
            "3     Engineer  Contractor                   102            False   \n",
            "4  Electrician   Architect                   142             True   \n",
            "\n",
            "   contains_important        urgency_classification   send_date  \\\n",
            "0               False  not urgent and not important  2016-07-10   \n",
            "1               False  not urgent and not important  2016-11-11   \n",
            "2               False  not urgent and not important  2019-10-11   \n",
            "3               False  not urgent and not important  2020-03-06   \n",
            "4               False          urgent and important  2016-11-10   \n",
            "\n",
            "             send_time      claim_type initial_priority  \\\n",
            "0  2016-07-10 17:19:31  administrative           medium   \n",
            "1  2016-11-11 09:49:27       technical             high   \n",
            "2  2019-10-11 12:25:15       technical              low   \n",
            "3  2020-03-06 17:12:27       technical              low   \n",
            "4  2016-11-10 17:10:03       technical             high   \n",
            "\n",
            "   number_of_attachments message_language  \n",
            "0                      0           German  \n",
            "1                      0          Spanish  \n",
            "2                      0          English  \n",
            "3                      0          English  \n",
            "4                      0          English  \n",
            "\n",
            "Statistiques descriptives:\n",
            "       number_of_characters  number_of_attachments\n",
            "count           2000.000000             2000.00000\n",
            "mean             164.285000                0.09950\n",
            "std              224.279697                0.45244\n",
            "min                0.000000                0.00000\n",
            "25%               48.750000                0.00000\n",
            "50%              121.500000                0.00000\n",
            "75%              208.000000                0.00000\n",
            "max             3470.000000               13.00000\n",
            "\n",
            "Valeurs manquantes par colonne:\n",
            "sender                    2\n",
            "receiver                  1\n",
            "number_of_characters      0\n",
            "contains_urgent           0\n",
            "contains_important        0\n",
            "urgency_classification    0\n",
            "send_date                 0\n",
            "send_time                 0\n",
            "claim_type                0\n",
            "initial_priority          0\n",
            "number_of_attachments     0\n",
            "message_language          0\n",
            "dtype: int64\n",
            "\n",
            "2. Prétraitement des données\n",
            "Variable cible: urgency_classification\n",
            "Distribution de la variable cible:\n",
            "urgency_classification\n",
            "not urgent and not important    1706\n",
            "not urgent and important         176\n",
            "urgent and important              59\n",
            "urgent and not important          59\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Variables catégorielles: ['sender', 'receiver', 'contains_urgent', 'contains_important', 'send_date', 'send_time', 'claim_type', 'initial_priority', 'message_language']\n",
            "Variables numériques: ['number_of_characters', 'number_of_attachments']\n",
            "\n",
            "Dimensions de l'ensemble d'entraînement: (1600, 11)\n",
            "Dimensions de l'ensemble de test: (400, 11)\n",
            "\n",
            "3. Entraînement et évaluation des modèles\n",
            "\n",
            "Résultats de la validation croisée (5-fold):\n",
            "Régression Logistique: Accuracy = 0.8819 (±0.0072)\n",
            "Random Forest: Accuracy = 0.8825 (±0.0037)\n",
            "Gradient Boosting: Accuracy = 0.8856 (±0.0054)\n",
            "\n",
            "4. Benchmarking des modèles\n",
            "\n",
            "Performances sur l'ensemble de test:\n",
            "                  Modèle  Accuracy  Precision  Recall  F1-Score\n",
            "1          Random Forest    0.8750   0.840216  0.8750  0.835513\n",
            "2      Gradient Boosting    0.8750   0.840216  0.8750  0.835513\n",
            "0  Régression Logistique    0.8725   0.836589  0.8725  0.832588\n",
            "\n",
            "Meilleur modèle: Random Forest\n",
            "\n",
            "5. Analyse détaillée du meilleur modèle\n",
            "\n",
            "Rapport de classification:\n",
            "                              precision    recall  f1-score   support\n",
            "\n",
            "    not urgent and important       0.70      0.20      0.31        35\n",
            "not urgent and not important       0.88      1.00      0.93       341\n",
            "        urgent and important       1.00      0.25      0.40        12\n",
            "    urgent and not important       0.00      0.00      0.00        12\n",
            "\n",
            "                    accuracy                           0.88       400\n",
            "                   macro avg       0.64      0.36      0.41       400\n",
            "                weighted avg       0.84      0.88      0.84       400\n",
            "\n",
            "\n",
            "6. Tests de robustesse\n",
            "\n",
            "Test avec des données bruitées:\n",
            "Accuracy avec données bruitées: 0.8750\n",
            "Différence d'accuracy: 0.0000\n",
            "\n",
            "7. Analyse des erreurs\n",
            "Nombre total d'erreurs: 50 sur 400 échantillons de test (12.50%)\n",
            "\n",
            "Distribution des types d'erreurs:\n",
            "                        Réalité                    Prédiction  count\n",
            "0      not urgent and important  not urgent and not important     28\n",
            "1  not urgent and not important      not urgent and important      1\n",
            "2          urgent and important      not urgent and important      2\n",
            "3          urgent and important  not urgent and not important      7\n",
            "4      urgent and not important  not urgent and not important     12\n",
            "\n",
            "8. Courbes d'apprentissage\n",
            "Score d'entraînement final: 0.9998\n",
            "Score de validation final: 0.8800\n",
            "Différence (overfitting): 0.1197\n",
            "\n",
            "9. Sauvegarde du modèle pour implémentation\n",
            "Modèle sauvegardé sous 'best_claims_model.pkl'\n",
            "\n",
            "10. Simulation d'utilisation en production\n",
            "\n",
            "Test avec un exemple de nouvelle réclamation:\n",
            "Classe prédite: not urgent and not important\n",
            "Probabilités: [0.02 0.97 0.01 0.  ]\n",
            "Classe réelle: not urgent and not important\n",
            "\n",
            "Conclusion: Le modèle est prêt pour les tests en environnement de pré-production\n",
            "Prochaines étapes recommandées:\n",
            "1. Configurer un environnement de pré-production\n",
            "2. Exécuter des tests A/B comparant le modèle avec l'approche actuelle\n",
            "3. Surveiller les performances sur un sous-ensemble de données réelles\n",
            "4. Préparer une stratégie de mise à jour et maintenance du modèle\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold, learning_curve\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.metrics import classification_report, roc_curve, roc_auc_score, precision_recall_curve\n",
        "from sklearn.inspection import permutation_importance\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 1. Chargement des données\n",
        "print(\"1. Chargement et exploration des données\")\n",
        "\n",
        "df = pd.read_csv('claims_dataset.csv')\n",
        "\n",
        "\n",
        "print(f\"Dimensions du dataset: {df.shape}\")\n",
        "print(\"\\nAperçu des données:\")\n",
        "print(df.head())\n",
        "\n",
        "# Affichage des statistiques descriptives\n",
        "print(\"\\nStatistiques descriptives:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Vérification des valeurs manquantes\n",
        "print(\"\\nValeurs manquantes par colonne:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# 2. Prétraitement des données\n",
        "print(\"\\n2. Prétraitement des données\")\n",
        "\n",
        "# Supposons que la variable cible est 'urgency_classification'\n",
        "target = 'urgency_classification'\n",
        "print(f\"Variable cible: {target}\")\n",
        "print(f\"Distribution de la variable cible:\\n{df[target].value_counts()}\")\n",
        "\n",
        "# Identification des types de variables\n",
        "categorical_cols = df.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
        "categorical_cols.remove(target) if target in categorical_cols else None\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "print(f\"\\nVariables catégorielles: {categorical_cols}\")\n",
        "print(f\"Variables numériques: {numeric_cols}\")\n",
        "\n",
        "# Création des ensembles d'entraînement et de test\n",
        "X = df.drop(target, axis=1)\n",
        "y = df[target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(f\"\\nDimensions de l'ensemble d'entraînement: {X_train.shape}\")\n",
        "print(f\"Dimensions de l'ensemble de test: {X_test.shape}\")\n",
        "\n",
        "# Préprocesseur pour transformer les données\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_cols),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "    ])\n",
        "\n",
        "# 3. Création et entraînement des modèles\n",
        "print(\"\\n3. Entraînement et évaluation des modèles\")\n",
        "\n",
        "# Définition des modèles à tester\n",
        "models = {\n",
        "    'Régression Logistique': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# Stockage des résultats\n",
        "results = {}\n",
        "\n",
        "# Validation croisée et entraînement des modèles\n",
        "print(\"\\nRésultats de la validation croisée (5-fold):\")\n",
        "for name, model in models.items():\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
        "\n",
        "    # Validation croisée\n",
        "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
        "    print(f\"{name}: Accuracy = {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")\n",
        "\n",
        "    # Entraînement sur l'ensemble complet d'entraînement\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Prédictions sur l'ensemble de test\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    # Calcul des métriques\n",
        "    results[name] = {\n",
        "        'model': pipeline,\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision': precision_score(y_test, y_pred, average='weighted'),\n",
        "        'recall': recall_score(y_test, y_pred, average='weighted'),\n",
        "        'f1': f1_score(y_test, y_pred, average='weighted'),\n",
        "        'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "# 4. Évaluation des performances\n",
        "print(\"\\n4. Benchmarking des modèles\")\n",
        "print(\"\\nPerformances sur l'ensemble de test:\")\n",
        "\n",
        "# Tableau comparatif des performances\n",
        "perf_df = pd.DataFrame({\n",
        "    'Modèle': list(results.keys()),\n",
        "    'Accuracy': [results[m]['accuracy'] for m in results],\n",
        "    'Precision': [results[m]['precision'] for m in results],\n",
        "    'Recall': [results[m]['recall'] for m in results],\n",
        "    'F1-Score': [results[m]['f1'] for m in results]\n",
        "})\n",
        "\n",
        "print(perf_df.sort_values('F1-Score', ascending=False))\n",
        "\n",
        "# Identification du meilleur modèle (basé sur F1-score)\n",
        "best_model_name = perf_df.sort_values('F1-Score', ascending=False).iloc[0]['Modèle']\n",
        "best_model = results[best_model_name]['model']\n",
        "print(f\"\\nMeilleur modèle: {best_model_name}\")\n",
        "\n",
        "# 5. Analyse détaillée du meilleur modèle\n",
        "print(\"\\n5. Analyse détaillée du meilleur modèle\")\n",
        "\n",
        "# Rapport de classification détaillé\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "print(\"\\nRapport de classification:\")\n",
        "print(classification_report(y_test, y_pred_best))\n",
        "\n",
        "# 6. Tests de robustesse\n",
        "print(\"\\n6. Tests de robustesse\")\n",
        "\n",
        "# Test avec des données bruitées\n",
        "print(\"\\nTest avec des données bruitées:\")\n",
        "X_test_noisy = X_test.copy()\n",
        "for col in numeric_cols:\n",
        "    if col in X_test_noisy.columns:\n",
        "        # Ajouter du bruit gaussien (10% de l'écart-type)\n",
        "        noise = np.random.normal(0, 0.1 * X_test_noisy[col].std(), size=X_test_noisy[col].shape)\n",
        "        X_test_noisy[col] = X_test_noisy[col] + noise\n",
        "\n",
        "y_pred_noisy = best_model.predict(X_test_noisy)\n",
        "print(f\"Accuracy avec données bruitées: {accuracy_score(y_test, y_pred_noisy):.4f}\")\n",
        "print(f\"Différence d'accuracy: {accuracy_score(y_test, y_pred_best) - accuracy_score(y_test, y_pred_noisy):.4f}\")\n",
        "\n",
        "# 7. Analyse des erreurs\n",
        "print(\"\\n7. Analyse des erreurs\")\n",
        "y_proba = best_model.predict_proba(X_test)\n",
        "errors = X_test.iloc[np.where(y_pred_best != y_test)[0]]\n",
        "error_predictions = y_pred_best[np.where(y_pred_best != y_test)[0]]\n",
        "error_truth = y_test.iloc[np.where(y_pred_best != y_test)[0]]\n",
        "\n",
        "print(f\"Nombre total d'erreurs: {len(errors)} sur {len(X_test)} échantillons de test ({len(errors)/len(X_test)*100:.2f}%)\")\n",
        "\n",
        "if len(errors) > 0:\n",
        "    error_df = pd.DataFrame({\n",
        "        'Prédiction': error_predictions,\n",
        "        'Réalité': error_truth\n",
        "    })\n",
        "    print(\"\\nDistribution des types d'erreurs:\")\n",
        "    print(error_df.groupby(['Réalité', 'Prédiction']).size().reset_index(name='count'))\n",
        "\n",
        "# 8. Courbes d'apprentissage\n",
        "print(\"\\n8. Courbes d'apprentissage\")\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    best_model, X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 10),\n",
        "    scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "print(f\"Score d'entraînement final: {train_mean[-1]:.4f}\")\n",
        "print(f\"Score de validation final: {test_mean[-1]:.4f}\")\n",
        "print(f\"Différence (overfitting): {train_mean[-1] - test_mean[-1]:.4f}\")\n",
        "\n",
        "# 9. Sauvegarde du modèle\n",
        "print(\"\\n9. Sauvegarde du modèle pour implémentation\")\n",
        "# Sauvegarde du meilleur modèle\n",
        "joblib.dump(best_model, 'best_claims_model.pkl')\n",
        "print(\"Modèle sauvegardé sous 'best_claims_model.pkl'\")\n",
        "\n",
        "# 10. Simulation de déploiement\n",
        "print(\"\\n10. Simulation d'utilisation en production\")\n",
        "\n",
        "def predict_claim_priority(claim_data):\n",
        "    \"\"\"\n",
        "    Fonction pour simuler l'utilisation du modèle en production\n",
        "    Args:\n",
        "        claim_data: Dictionnaire contenant les données d'une réclamation\n",
        "    Returns:\n",
        "        Classe prédite et probabilités\n",
        "    \"\"\"\n",
        "    # Conversion en DataFrame\n",
        "    claim_df = pd.DataFrame([claim_data])\n",
        "\n",
        "    # Prédiction\n",
        "    prediction = best_model.predict(claim_df)[0]\n",
        "    probabilities = best_model.predict_proba(claim_df)[0]\n",
        "\n",
        "    return prediction, probabilities\n",
        "\n",
        "# Exemple d'une nouvelle réclamation\n",
        "print(\"\\nTest avec un exemple de nouvelle réclamation:\")\n",
        "# Utilisez un exemple réel de votre dataset\n",
        "new_claim = X_test.iloc[0].to_dict()\n",
        "predicted_class, probas = predict_claim_priority(new_claim)\n",
        "print(f\"Classe prédite: {predicted_class}\")\n",
        "print(f\"Probabilités: {probas}\")\n",
        "print(f\"Classe réelle: {y_test.iloc[0]}\")\n",
        "\n",
        "print(\"\\nConclusion: Le modèle est prêt pour les tests en environnement de pré-production\")\n",
        "print(\"Prochaines étapes recommandées:\")\n",
        "print(\"1. Configurer un environnement de pré-production\")\n",
        "print(\"2. Exécuter des tests A/B comparant le modèle avec l'approche actuelle\")\n",
        "print(\"3. Surveiller les performances sur un sous-ensemble de données réelles\")\n",
        "print(\"4. Préparer une stratégie de mise à jour et maintenance du modèle\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import joblib\n",
        "\n",
        "# Sauvegarde du meilleur modèle\n",
        "joblib.dump(models[best_model_name], 'urgent_model.pkl')\n",
        "print(\"✅ Modèle sauvegardé sous 'urgent_model.pkl'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsBIft4LjKW8",
        "outputId": "eb56fe3d-8f82-452c-e7e6-096cbb01acbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modèle sauvegardé sous 'urgent_model.pkl'\n"
          ]
        }
      ]
    }
  ]
}